{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1XR_tm1Cnf0nw1rQDH339-A1TlkSSs45A","authorship_tag":"ABX9TyOjX931zNDq4RyoUjHpt5qX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7EAvgAIKDfY1","colab_type":"code","outputId":"6b230409-7783-4d40-bb95-fc551bb9b7f9","executionInfo":{"status":"ok","timestamp":1590645286806,"user_tz":420,"elapsed":605,"user":{"displayName":"Claudia Ivett Núñez Martínez","photoUrl":"","userId":"05880194249777134217"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd'/content/drive/My Drive/ML'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/ML\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-vTzOdyZddLo","colab_type":"code","outputId":"17513e9b-eba6-4731-cde6-0098fafb755d","executionInfo":{"status":"error","timestamp":1590647611123,"user_tz":420,"elapsed":1719,"user":{"displayName":"Claudia Ivett Núñez Martínez","photoUrl":"","userId":"05880194249777134217"}},"colab":{"base_uri":"https://localhost:8080/","height":394}},"source":["import glob #used to import seach files\n","import pickle #used for binary files\n","import numpy #used for reshape network input\n","import matplotlib.pyplot as plt # used for metrics plots\n","from music21 import converter, instrument, note, chord #used for midi files processing\n","from keras.utils import np_utils\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.layers import Activation\n","from keras.callbacks import ModelCheckpoint\n","\n","timestep = 0.25\n","sequence_length = int(8 / timestep)\n","\n","def get_notes():\n","    music_data = glob.glob(\"midi_files/*.mid\")\n","    notes = []    \n","\n","    for file in music_data:\n","        # Get the full score\n","        print(\"Parsing %s\" % file)\n","        try:\n","            all_score = converter.parse(file)\n","        except IndexError as e:\n","            print(\"Could not parse \" + str(file))\n","            print(e)\n","            continue\n","        \n","        # Get the principal melody section\n","        notes_to_parse = None        \n","        score_parts = instrument.partitionByInstrument(all_score) # get instruments parts (monophonic approach)\n","        if score_parts: # file has instrument parts\n","            notes_to_parse = score_parts.parts[0].recurse()\n","        else: # file has notes in a flat structure\n","            notes_to_parse = all_score.flat.notes\n","        \n","        # Parse notes from principal melody to get pitch and duration\n","        prev_offset = 0.0\n","        for element in notes_to_parse:\n","            if isinstance(element, note.Note) or isinstance(element, chord.Chord):\n","                \n","                duration = element.duration.quarterLength # each note is played in 0.25s intervals\n","                \n","                '''if(float(duration) > timestep): #truncate\n","                    duration = timestep '''\n","                if isinstance(element, note.Note):\n","                    # Get pitch from note\n","                    name = element.pitch  \n","                elif isinstance(element, chord.Chord):\n","                    # Get pitch for each chord note\n","                    name = \".\".join(str(n) for n in element.normalOrder)\n","                \n","                # Add note with the format name$duration\n","                notes.append(f\"{name}${duration}\")\n","\n","                # Calculate rest time to fill a bit.\n","                # Get the difference between last note start time and current note\n","                # start ttime and the fill that space with rest notes\n","                rest_notes =  int((element.offset - prev_offset) / timestep - 1)\n","                for _ in range(0, rest_notes):\n","                        notes.append(\"NULL\")\n","                prev_offset = element.offset;\n","\n","        # Save notes\n","        with open('data/notes', 'wb') as filepath:\n","              pickle.dump(notes, filepath) #set notes into a bytestream\n","\n","    return notes\n","    \n","def prepare_sequences(notes, n_vocab):\n","    # Mapping notes to integer-based data\n","    # Step 1: Get all pitch notes\n","    pitchnames = sorted(set(item for item in notes))\n","    # Step 2: Create a dictionary to map pitches to integers\n","    note_to_int = dict((note, number+1) for number, note in enumerate(pitchnames)) # +1 to consider rest notes\n","    note_to_int[\"NULL\"] = 0 # this is for rests times\n","    \n","    # Create input sequences and the corresponding outputs\n","    network_input = []\n","    network_output = []\n","    for i in range(0, len(notes) - sequence_length, 1): #the limit is because it won't be an output if there are sequence_length elements reamining\n","        sequence_in = notes[i:i + sequence_length]\n","        sequence_out = notes[i + sequence_length]\n","        network_input.append([note_to_int[char] for char in sequence_in]) #collects all input sequences but in the integer form. list of n lists with sequence_length elements in each one\n","        network_output.append(note_to_int[sequence_out])  #collects all output notes but in the integer form\n","    \n","    n_patterns = len(network_input)\n","\n","    # Reshape the input into a format compatible with LSTM layers. From horizontal to vertical form\n","    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n","    # Normalize input. Get values from 0 to 1 representing our \"classes\" into a range from 0 to 1\n","    network_input = network_input / float(n_vocab)\n","    \n","    # One-hot encoding for output.\n","    network_output = np_utils.to_categorical(network_output)\n","\n","    return (network_input, network_output)\n","\n","\n","def create_network(network_input, n_vocab):\n","    print(\"Input shape  \", network_input.shape)\n","    print(\"Output shape \", n_vocab)\n","    model = Sequential()\n","    model.add(LSTM(\n","        512,\n","        input_shape=(network_input.shape[1], network_input.shape[2]),\n","        recurrent_dropout=0.4,\n","        return_sequences=True\n","    ))\n","    model.add(Dropout(0.4))\n","    model.add(LSTM(512))\n","    #model.add(Dropout(0.5))\n","    #model.add(LSTM(512)) #number of nodes\n","    #model.add(Dense(256)) #number of nodes\n","    #model.add(Dropout(0.5))\n","    model.add(Dense(n_vocab))\n","    model.add(Activation('softmax')) \n","    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n","    model.summary()\n","    return model\n","\n","def train(model, network_input,network_output):\n","    # File in which the model will be saved\n","    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n","    checkpoint = ModelCheckpoint(\n","        filepath,\n","        monitor='loss',\n","        verbose=0,\n","        save_best_only=True,\n","        mode='min'\n","    )\n","    callbacks_list = [checkpoint]\n","\n","    model.fit(network_input, network_output, epochs=100, batch_size=32, callbacks=callbacks_list)\n","\n","def train_process():\n","    # Get data\n","    #notes = get_notes()\n","    with open('data/notes', 'rb') as filepath:\n","        notes = pickle.load(filepath)\n","    '''print(notes)'''\n","    print(\"Total notes = \" + str(len(notes)))\n","    \n","    # Get amount of different pitch names\n","    n_vocab = len(set(notes))\n","    print(\"n_vocab = \" + str(n_vocab))\n","\n","    # Get input and output sequences. It returns the input data with a format compatible with network\n","    network_input, network_output = prepare_sequences(notes, n_vocab)\n","\n","    # Generate model\n","    model = create_network(network_input, n_vocab)\n","\n","    # Train model\n","    train(model, network_input, network_output)\n","    \n","\n","if __name__ == \"__main__\":\n","    train_process()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Total notes = 334444\n","n_vocab = 3689\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-ee4d85d1fbd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mtrain_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-ee4d85d1fbd5>\u001b[0m in \u001b[0;36mtrain_process\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# Get input and output sequences. It returns the input data with a format compatible with network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# Generate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-ee4d85d1fbd5>\u001b[0m in \u001b[0;36mprepare_sequences\u001b[0;34m(notes, n_vocab)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0msequence_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0msequence_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mnetwork_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnote_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#collects all input sequences but in the integer form. list of n lists with sequence_length elements in each one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mnetwork_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#collects all output notes but in the integer form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"aRfgTzzkjkH3","colab_type":"code","outputId":"aae6f5e6-2b6f-4501-adb5-f564c8425ead","executionInfo":{"status":"ok","timestamp":1590604650473,"user_tz":420,"elapsed":11298,"user":{"displayName":"Claudia Ivett Núñez Martínez","photoUrl":"","userId":"05880194249777134217"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.6 GB  | Proc size: 354.8 MB\n","GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"],"name":"stdout"}]}]}